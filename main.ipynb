{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import muspy\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "import cv2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Activation, Dropout, BatchNormalization, Input, Flatten, Reshape, Conv2DTranspose, Conv2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:37.148253Z",
     "iopub.execute_input": "2023-01-24T06:28:37.151901Z",
     "iopub.status.idle": "2023-01-24T06:28:37.172181Z",
     "shell.execute_reply.started": "2023-01-24T06:28:37.151844Z",
     "shell.execute_reply": "2023-01-24T06:28:37.163447Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "DATA_PATHS = ['/kaggle/input/trap-midi/', '/kaggle/input/randb-midi/', '/kaggle/input/slap-house/', '/kaggle/input/tranceandtechno/', '/kaggle/input/latin-midi/']\n",
    "num_genres = len(DATA_PATHS)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:37.179618Z",
     "iopub.execute_input": "2023-01-24T06:28:37.183393Z",
     "iopub.status.idle": "2023-01-24T06:28:37.200307Z",
     "shell.execute_reply.started": "2023-01-24T06:28:37.183321Z",
     "shell.execute_reply": "2023-01-24T06:28:37.198429Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img_shape = (48, 48, 5)\n",
    "gen_shape = (6, 6, 256)\n",
    "\n",
    "\n",
    "def retrieve_midi_file(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        raise ValueError(\"Midi File Paths cannot be found!\")\n",
    "    \n",
    "    midi_file = []\n",
    "    for midi in os.listdir(filepath):\n",
    "        if midi.lower().endswith((\"midi\",\"mid\")):\n",
    "            midi_file.append(filepath+midi)\n",
    "    return midi_file\n",
    "\n",
    "\n",
    "def muspy_read_midi_file(midi_file, resolution=24):\n",
    "    songs = []\n",
    "    for song in midi_file:\n",
    "        file = muspy.read(song)\n",
    "        file.clip(lower=64, upper=127)\n",
    "        songs.append(muspy.adjust_resolution(file, resolution))\n",
    "    return songs\n",
    "\n",
    "\n",
    "def save_imgs(epoch, velocity=True):\n",
    "    \n",
    "    \n",
    "    image_file = \"./images\"\n",
    "    \n",
    "    if not os.path.exists(image_file):\n",
    "        os.mkdir(image_file)\n",
    "    \n",
    "    r, c = 2,2\n",
    "    noise = np.random.normal(0, 1, (r*c, 100))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "    \n",
    "    if velocity == True:\n",
    "        gen_imgs = (63.5 * gen_imgs) + 63.5\n",
    "        gen_imgs = np.squeeze(gen_imgs)\n",
    "        gen_imgs = gen_imgs.astype(int)\n",
    "        \n",
    "    else:\n",
    "        gen_imgs = (0.5 * gen_imgs) + 0.5\n",
    "        gen_imgs = np.squeeze(gen_imgs)\n",
    "        gen_imgs = (gen_imgs+0.5).astype(int)\n",
    "        \n",
    "   \n",
    "        for m in range(num_genres):\n",
    "            fig, axs = plt.subplots(r, c)\n",
    "            count = 0\n",
    "            for j in range(r):\n",
    "                for k in range(c):\n",
    "                    axs[j, k].imshow(gen_imgs[count,:,:,m], cmap='gray')\n",
    "                    axs[j, k].axis('off')\n",
    "                    count += 1\n",
    "                if m == 0:\n",
    "                    ch = \"hip\"\n",
    "                if m == 1:\n",
    "                    ch = \"randb\"\n",
    "                plt.savefig(\"images/GAN_{epoch}_{ch}.png\".format(epoch=epoch, ch = ch))\n",
    "                plt.close()\n",
    "\n",
    "            \n",
    "def transpose_to_Amin_or_Cmaj(song):\n",
    "    AMin_key_interval = {\n",
    "                    \"B\": -2,\n",
    "                    \"Asharp\": -1,\n",
    "                    \"Gsharp\": 1,\n",
    "                    \"G\": 2,\n",
    "                    \"Fsharp\": 3,\n",
    "                    \"F\": 4,\n",
    "                    \"E\": 5,\n",
    "                    \"Dsharp\": 6,\n",
    "                    \"D\": 7,\n",
    "                    \"Csharp\": 8,\n",
    "                    \"C\": 9\n",
    "    }\n",
    "    CMaj_key_interval = {\n",
    "                    \"B\": 1,\n",
    "                    \"Asharp\": 2,\n",
    "                    \"A\": 3,\n",
    "                    \"Gsharp\": 4,\n",
    "                    \"G\": 5,\n",
    "                    \"Fsharp\": 6,\n",
    "                    \"F\": -5,\n",
    "                    \"E\": -4,\n",
    "                    \"Dsharp\": -3,\n",
    "                    \"D\": -2,\n",
    "                    \"Csharp\": -1,\n",
    "    }      \n",
    "    \n",
    "    \n",
    "    key = song.metadata.source_filename.split('-')[2].split(' ')[1]\n",
    "    mode = song.metadata.source_filename.split('-')[2].split(' ')[2].split('.')[0]\n",
    "    \n",
    "    if mode == \"Min\":\n",
    "        \n",
    "        if key != \"A\":\n",
    "            print(f\"Current Key is: {key}min, transposing by {AMin_key_interval[key]}\")\n",
    "            song.transpose(AMin_key_interval[key])\n",
    "            \n",
    "    if mode == \"Maj\":\n",
    "        \n",
    "        if key != \"C\":\n",
    "            print(f\"Current Key is: {key}maj, transposing by {CMaj_key_interval[key]}\")\n",
    "            song.transpose(CMaj_key_interval[key])\n",
    "        \n",
    "            \n",
    "    return song\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:37.206560Z",
     "iopub.execute_input": "2023-01-24T06:28:37.207197Z",
     "iopub.status.idle": "2023-01-24T06:28:37.243480Z",
     "shell.execute_reply.started": "2023-01-24T06:28:37.207149Z",
     "shell.execute_reply": "2023-01-24T06:28:37.241995Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_generator():\n",
    "    #Input - Noise\n",
    "    #Output - Fake Image with label True to fake discriminator\n",
    "    \n",
    "    noise_shape = (100,)\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(np.prod(gen_shape), input_shape=noise_shape))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Reshape(gen_shape))\n",
    "\n",
    "    model.add(Conv2DTranspose(128, 3, (2,2), padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Conv2DTranspose(64, 3, (2,2), padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Conv2DTranspose(5, 3, (2,2), padding=\"same\", activation=\"tanh\"))\n",
    "    \n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)\n",
    "    model.summary()\n",
    "    \n",
    "    return Model(noise,img)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:57.018720Z",
     "iopub.execute_input": "2023-01-24T06:28:57.019753Z",
     "iopub.status.idle": "2023-01-24T06:28:57.029756Z",
     "shell.execute_reply.started": "2023-01-24T06:28:57.019714Z",
     "shell.execute_reply": "2023-01-24T06:28:57.028346Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def build_discriminator():\n",
    "    #Input - Image\n",
    "    #Output - Prediction of Image True/False\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, 3, (2,2), padding=\"same\", input_shape=img_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(128, 3, (2,2), padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Conv2D(256, 3, (2,2), padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    \n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "    model.summary()\n",
    "    \n",
    "    return Model(img, validity)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:57.483544Z",
     "iopub.execute_input": "2023-01-24T06:28:57.484261Z",
     "iopub.status.idle": "2023-01-24T06:28:57.494050Z",
     "shell.execute_reply.started": "2023-01-24T06:28:57.484223Z",
     "shell.execute_reply": "2023-01-24T06:28:57.492787Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train(sequence, epochs, batch_size=64, save_interval=50, velocity=True):\n",
    "    \n",
    "    model_file = \"./model\"\n",
    "    loss_img = \"./loss_img\"\n",
    "    \n",
    "    if not os.path.exists(model_file):\n",
    "        os.mkdir(model_file)\n",
    "    if not os.path.exists(loss_img):\n",
    "        os.mkdir(loss_img)\n",
    "        \n",
    "    #Normalize to -1 to 1\n",
    "    if velocity == True:\n",
    "        sequence = (sequence-63.5)/63.5\n",
    "    else:\n",
    "        sequence = (sequence-0.5)/0.5\n",
    "    \n",
    "    dloss = []\n",
    "    gloss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "        idx = np.random.randint(0, sequence.shape[0], batch_size)\n",
    "        imgs = sequence[idx]\n",
    "        \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        \n",
    "        gen_imgs = generator.predict(noise)\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, np.ones((batch_size, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((batch_size, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "        end = time.time()\n",
    "        print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "        print(f\"Time taken = {end-start}\")\n",
    "        dloss.append(d_loss[0])\n",
    "        gloss.append(g_loss)\n",
    "        \n",
    "        if epoch % save_interval == 0:\n",
    "            #save_imgs(epoch, velocity=velocity)\n",
    "            \n",
    "            plt.plot(dloss, label='d_loss')\n",
    "            plt.plot(gloss, label='g_loss')\n",
    "            plt.xlabel('epochs')\n",
    "            plt.ylabel('loss')\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.savefig(f\"{loss_img}/loss_{epoch}.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            generator.save(f'{model_file}/generator_model_{epoch}.h5')\n",
    "            \n",
    "def get_lowest_note(song):\n",
    "    for num, row in enumerate(song):\n",
    "        if any(row != 0):\n",
    "            return num\n",
    "        \n",
    "def back_to_format(song):\n",
    "    pass\n",
    "    #work in progress\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #Loading midi files\n",
    "    \n",
    "    midi_file = retrieve_midi_file(DATA_PATHS[0])\n",
    "    midi_file += retrieve_midi_file(DATA_PATHS[1])\n",
    "    midi_file += retrieve_midi_file(DATA_PATHS[2])\n",
    "    midi_file += retrieve_midi_file(DATA_PATHS[3])\n",
    "    midi_file += retrieve_midi_file(DATA_PATHS[4])\n",
    "\n",
    "    velocity = True\n",
    "    \n",
    "    #Reading midi files in muspy format and clip velocity and setting resolution to 12\n",
    "    songs = muspy_read_midi_file(midi_file, resolution=12)\n",
    "    \n",
    "    sequences = []\n",
    "    \n",
    "    for song in songs:\n",
    "        #Current preprocessing song\n",
    "        print(f\"Preprocessing {song.metadata.source_filename}\")\n",
    "        \n",
    "        #Transposing song to Cmaj or Amin key\n",
    "        \n",
    "        if song.metadata.source_filename.split(\"-\")[0] == \"Cymatics\":\n",
    "            \n",
    "            song = transpose_to_Amin_or_Cmaj(song)\n",
    "        \n",
    "        #Convert to muspy pianoroll representation\n",
    "        song = song.to_pianoroll_representation(encode_velocity=True)\n",
    "        \n",
    "        #truncate song if song> 8sec (Remove if update fails)\n",
    "        # 1sec = 24units\n",
    "        if song.shape[0]>192:\n",
    "            song = song[:192]\n",
    "            \n",
    "        #Convert shape into Pitch(X-axis)=128, Time(Y-axis)=48\n",
    "        song = cv2.resize(song, (128,48), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        #Transpose the shape Time(X-axis)=48, Pitch(Y-axis)=128\n",
    "        song = song.transpose(1,0)\n",
    "        \n",
    "        #Extract a total of 4 octave range\n",
    "        low = get_lowest_note(song)\n",
    "        song = song[low:low+48]\n",
    "        \n",
    "        sequences.append(song)\n",
    "        \n",
    "    stack1 = np.stack(sequences[:100])\n",
    "    stack2 = np.stack(sequences[100:200])\n",
    "    stack3 = np.stack(sequences[200:300])\n",
    "    stack4 = np.stack(sequences[300:400])\n",
    "    stack5 = np.stack(sequences[400:])\n",
    "         \n",
    "    exp_stack1 = np.expand_dims(stack1, axis=3)\n",
    "    exp_stack2 = np.expand_dims(stack2, axis=3)\n",
    "    exp_stack3 = np.expand_dims(stack3, axis=3)\n",
    "    exp_stack4 = np.expand_dims(stack4, axis=3)\n",
    "    exp_stack5 = np.expand_dims(stack5, axis=3)\n",
    "        \n",
    "    sequence = np.concatenate((exp_stack1, exp_stack2, exp_stack3, exp_stack4, exp_stack5), axis=3)\n",
    "    print(f\"Sequence Shape = {sequence.shape}\")\n",
    "        \n",
    "    gen_optimizer = Adam(5e-6, 0.5)\n",
    "    disc_optimizer = Adam(5e-6, 0.5)\n",
    "    discriminator = build_discriminator()\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=disc_optimizer, metrics=['accuracy'])\n",
    "        \n",
    "    generator = build_generator()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
    "        \n",
    "    z = Input(shape=(100,))\n",
    "    img = generator(z)\n",
    "    discriminator.trainable = False\n",
    "    valid = discriminator(img)\n",
    "        \n",
    "    combined = Model(z, valid)\n",
    "    combined.compile(loss=\"binary_crossentropy\", optimizer=gen_optimizer)\n",
    "        \n",
    "    train(sequence, epochs=500000, batch_size=32, save_interval=1000, velocity=velocity)\n",
    "    "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-24T06:28:58.199958Z",
     "iopub.execute_input": "2023-01-24T06:28:58.200868Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-23T10:51:46.498494Z",
     "iopub.execute_input": "2023-01-23T10:51:46.499304Z",
     "iopub.status.idle": "2023-01-23T10:51:46.507449Z",
     "shell.execute_reply.started": "2023-01-23T10:51:46.499275Z",
     "shell.execute_reply": "2023-01-23T10:51:46.506278Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-23T10:51:52.395241Z",
     "iopub.execute_input": "2023-01-23T10:51:52.395569Z",
     "iopub.status.idle": "2023-01-23T10:51:52.403654Z",
     "shell.execute_reply.started": "2023-01-23T10:51:52.395544Z",
     "shell.execute_reply": "2023-01-23T10:51:52.402115Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}